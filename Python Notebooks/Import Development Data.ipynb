{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Import Development Data\n",
    "## Brian Goggin\n",
    "In this assignment, I import data from the San Francisco development pipeline from SF Open data's API. I import quarterly data from the fourth quarter of 2012 to the fourth quarter of 2016. In the first section of the notebook, I import, append, and clean the data. In other notebooks, I use this data to explore development activity in SF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Import and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the packages necessary for calling an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import json    # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "import pprint  # library for making Python data structures readable\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SF Planning Department releases this data quarterly. Quarterly reports go back all the way to 2012. However, this data is messy and inconsistent. Therefore, each quarterly file has to be imported individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q12017 = 'https://data.sfgov.org/resource/6dqp-5d5y.json'\n",
    "Q42016 = 'https://data.sfgov.org/resource/nba4-2xjv.json'\n",
    "Q32016 = 'https://data.sfgov.org/resource/qwfj-9mts.json'\n",
    "Q22016 = 'https://data.sfgov.org/resource/3n2r-nn4r.json'\n",
    "Q12016 = 'https://data.sfgov.org/resource/6iid-qfaz.json'\n",
    "Q42015 = 'https://data.sfgov.org/resource/6jnk-ty34.json'\n",
    "Q32015 = 'https://data.sfgov.org/resource/8qip-pyye.json'\n",
    "Q22015 = 'https://data.sfgov.org/resource/b6nb-tyvq.json'\n",
    "Q12015 = 'https://data.sfgov.org/resource/auw5-vpae.json'\n",
    "Q42014 = 'https://data.sfgov.org/resource/ia2z-a7eh.json'\n",
    "Q32014 = 'https://data.sfgov.org/resource/9xqb-guwy.json' #Problem - this json does not have best date information that the raw csv file does\n",
    "Q22014 = 'https://data.sfgov.org/resource/tkr2-mzci.json'\n",
    "Q12014 = 'https://data.sfgov.org/resource/fq62-z4pc.json'\n",
    "Q42013 = 'https://data.sfgov.org/resource/s42z-x9np.json'\n",
    "Q32013 = 'https://data.sfgov.org/resource/h2ky-3rra.json'\n",
    "Q22013 = 'https://data.sfgov.org/resource/ixti-hd8i.json'\n",
    "Q12013 = 'https://data.sfgov.org/resource/662u-bk2r.json'\n",
    "Q42012 = 'https://data.sfgov.org/resource/fpzh-9ii5.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I define a function for importing the data from each API into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importdata(quarter, quartervalue, field1, field2, field3, field4, \n",
    "               field5, field6, field7, field8, field9, field10, field11, \n",
    "               field12, geogfield1, geogfield2):\n",
    "    '''\n",
    "    This function calls the API endpoint quarter and returns a dataframe with the desired columns.\n",
    "    field'n' = 'name' represent the desired fields as they are named at the API endpoint\n",
    "    '''\n",
    "    \n",
    "    def includekey(field):\n",
    "        '''\n",
    "        This function takes a given field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if field in item.keys():\n",
    "                list.append(item[field])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "\n",
    "    def include_coor_key(one, two):\n",
    "        '''\n",
    "        This function takes a given geographic field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if one in item.keys():\n",
    "                list.append(item[one][two])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "    \n",
    "    response = requests.get(quarter)\n",
    "    results = response.text\n",
    "    data = json.loads(results) #data is a list at this point\n",
    "    \n",
    "    #import fields\n",
    "    d = {}\n",
    "    d['lot_number'] = includekey(field1)\n",
    "    d['address'] = includekey(field2)\n",
    "    d['status'] = includekey(field3)\n",
    "    d['latest_date'] = includekey(field4)\n",
    "    d['units'] = includekey(field5)\n",
    "    d['net_units'] = includekey(field6)\n",
    "    d['affordable_units'] = includekey(field7)\n",
    "    d['net_affordable_units'] = includekey(field8)\n",
    "    d['zone'] = includekey(field9)\n",
    "    d['desc'] = includekey(field10)\n",
    "    d['comm_sqft'] = includekey(field11)\n",
    "    d['comm_sqft_net'] = includekey(field12)\n",
    "    d['lat_lon'] = include_coor_key(geogfield1, geogfield2)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    df['quarter'] = quartervalue\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the data (one for each quarter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q12017df = importdata(Q12017, 'Q12017', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'net_units', 'aff_units', 'net_aff_units', 'zoning_sim', 'pln_desc', 'total_gsf', 'net_gsf', 'location', 'coordinates')\n",
    "Q42016df = importdata(Q42016, 'Q42016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordablenet', 'zoning', 'dbi_desc', 'total_gsf', 'net_gsf', 'location', 'coordinates')\n",
    "Q32016df = importdata(Q32016, 'Q32016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affnet', 'zoning_sim', 'dbidesc', 'total_gsf', 'net_gsf', 'location', 'coordinates')\n",
    "Q22016df = importdata(Q22016, 'Q22016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'aff', 'affnet', 'zoning_sim', 'dbi_desc', 'total_gsf', 'net_gsf', 'location', 'coordinates')   \n",
    "#Q12016df = importdata(Q12016, 'Q12016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordable_net', 'zoning', 'dbidesc', 'total_gsf', 'net_gsf', 'location', 'coordinates')\n",
    "Q42015df = importdata(Q42015, 'Q42015','apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordab_1', 'zoning_sim','dbidesc', 'total_gsf', 'net_gsf', 'geography', 'coordinates')\n",
    "Q32015df = importdata(Q32015, 'Q32015','apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordablenet', 'zoning_sim', 'dbidesc', 'total_gsf', 'net_gsf', 'location', 'coordinates')\n",
    "Q22015df = importdata(Q22015,'Q22015', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordablenet', 'zoning_sim', 'dbidesc', 'total_gsf', 'net_gsf', 'geography', 'coordinates')\n",
    "Q12015df = importdata(Q12015, 'Q12015','blklot', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'aff', 'affnet', 'zoning_sim','dbidesc', 'total_gsf', 'net_gsf', 'geography', 'coordinates')\n",
    "Q42014df = importdata(Q42014, 'Q42014','blklot', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affnet', 'zoning_sim', 'dbidesc', 'total_gsf', 'net_gsf', 'geography', 'coordinates')\n",
    "Q32014df = importdata(Q32014, 'Q32014','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affnet', 'zoning', 'dbi_project_description', 'total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n",
    "Q22014df = importdata(Q22014, 'Q22014','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'planning_project_description', 'total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n",
    "Q12014df = importdata(Q12014,'Q12014', 'block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified','planning_project_description', 'total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n",
    "Q42013df = importdata(Q42013,'Q42013', 'block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified','planning_project_description', 'total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n",
    "Q32013df = importdata(Q32013, 'Q32013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'planning_project_description', 'total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n",
    "Q22013df = importdata(Q22013, 'Q22013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'dbi_project_description', 'total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n",
    "Q12013df = importdata(Q12013, 'Q12013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'dbi_project_description','total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n",
    "Q42012df = importdata(Q42012, 'Q42012','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'dbi_project_description','total_gsf_commercial', 'net_added_sf', 'location_1', 'coordinates')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Q1 2016\n",
    "Define a second import function for just Q1 2016 - need different importation because it is missing summation for commercial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def importdata(quarter, quartervalue, field1, field2, field3, \n",
    "               field4, field5, field6, field7, field8, field9, field10, \n",
    "               field11, field12, field13, field14, field15, field16, field17, field18, field19, \n",
    "               field20, field21, field22, geogfield1, geogfield2):\n",
    "    '''\n",
    "    This function calls the API endpoint quarter and returns a dataframe with the desired columns.\n",
    "    field'n' = 'name' represent the desired fields as they are named at the API endpoint\n",
    "    '''\n",
    "    \n",
    "    def includekey(field):\n",
    "        '''\n",
    "        This function takes a given field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if field in item.keys():\n",
    "                list.append(item[field])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "\n",
    "    def include_coor_key(one, two):\n",
    "        '''\n",
    "        This function takes a given geographic field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if one in item.keys():\n",
    "                list.append(item[one][two])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "    \n",
    "    response = requests.get(quarter)\n",
    "    results = response.text\n",
    "    data = json.loads(results) #data is a list at this point\n",
    "    \n",
    "    #import fields\n",
    "    d = {}\n",
    "    d['lot_number'] = includekey(field1)\n",
    "    d['address'] = includekey(field2)\n",
    "    d['status'] = includekey(field3)\n",
    "    d['latest_date'] = includekey(field4)\n",
    "    d['units'] = includekey(field5)\n",
    "    d['net_units'] = includekey(field6)\n",
    "    d['affordable_units'] = includekey(field7)\n",
    "    d['net_affordable_units'] = includekey(field8)\n",
    "    d['zone'] = includekey(field9)\n",
    "    d['desc'] = includekey(field10)\n",
    "    d['retail'] = includekey(field11)\n",
    "    d['retail_net'] = includekey(field12)\n",
    "    d['office'] = includekey(field13)\n",
    "    d['office_net'] = includekey(field14)\n",
    "    d['ind'] = includekey(field15)\n",
    "    d['ind_net'] = includekey(field16)\n",
    "    d['med'] = includekey(field17)\n",
    "    d['med_net'] = includekey(field18)\n",
    "    d['vis'] = includekey(field19)\n",
    "    d['vis_net'] = includekey(field20)\n",
    "    d['cie'] = includekey(field21)\n",
    "    d['cie_net'] = includekey(field22)\n",
    "    d['lat_lon'] = include_coor_key(geogfield1, geogfield2)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    df['quarter'] = quartervalue\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q12016df = importdata(Q12016, 'Q12016', 'apn', 'nameaddr', 'beststat', \n",
    "                      'bestdate', 'units', 'unitsnet', 'affordable', \n",
    "                      'affordable_net', 'zoning', 'dbidesc', \n",
    "                      'retailcomm_proposed','retailcomm_net', 'office_proposed', 'office_net', \n",
    "                      'industrial_proposed', 'industrial_net', 'medical_proposed', \n",
    "                      'medical_net', 'visitor_proposed', 'visitor_net', \n",
    "                      'cie_proposed', 'cie_net', 'location', 'coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert variables to floats\n",
    "vars = ['retail', 'office', 'ind', 'med', 'vis', 'cie']\n",
    "\n",
    "for i in vars:\n",
    "    Q12016df[i] = Q12016df[i].astype(int)\n",
    "    Q12016df[i+'_net'] = Q12016df[i+'_net'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define sums for total and net commercial square footage\n",
    "Q12016df['comm_sqft'] = Q12016df[['retail', 'office', 'ind', 'med', 'vis', 'cie']].sum(axis = 1)\n",
    "Q12016df['comm_sqft_net'] = Q12016df[['retail_net', 'office_net', 'ind_net', 'med_net', 'vis_net', 'cie_net']].sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append Data Together\n",
    "Append the dataframes together for one panel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16666, 26)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Append data together\n",
    "quarters = [Q42016df, Q32016df, Q22016df, Q12016df, Q42015df, Q32015df, Q22015df, Q12015df, Q42014df, \n",
    "            Q32014df, Q22014df, Q12014df, Q42013df, Q32013df, Q22013df, Q12013df,\n",
    "           Q42012df]\n",
    "full_df = Q12017df.append(quarters)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data after appending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean affordable units variables\n",
    "full_df.loc[full_df['affordable_units'] == '0E-11', 'affordable_units'] = 0\n",
    "full_df.loc[full_df['net_affordable_units'] == '0E-11', 'net_affordable_units'] = 0\n",
    "#full_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean data after importing\n",
    "full_df['lon'] = full_df['lat_lon'].astype(str).str.split(',').str[0].str.strip('[')\n",
    "full_df['lat'] = full_df['lat_lon'].astype(str).str.split(',').str[1].str.strip(']')\n",
    "full_df['lon'] = full_df['lon'].astype(float)\n",
    "full_df['lat'] = full_df['lat'].astype(float)\n",
    "full_df['net_units'] = full_df['net_units'].astype(float) #convert to float\n",
    "full_df['units'] = full_df['units'].astype(float) #convert to float\n",
    "full_df['net_affordable_units'] = full_df['net_affordable_units'].astype(float) #convert to float\n",
    "full_df['affordable_units'] = full_df['affordable_units'].astype(float) #convert to float\n",
    "full_df['lot_number'] = full_df['lot_number'].str.strip('APN ').str.zfill(7)\n",
    "full_df['comm_sqft'] = full_df['comm_sqft'].astype(float) #convert to float\n",
    "full_df['comm_sqft_net'] = full_df['comm_sqft_net'].astype(float) #convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary for which quarter a project is in and then sort by quarters\n",
    "quarter_dict = {'Q12017': 19, 'Q42016': 18, 'Q32016': 17, 'Q22016': 16, 'Q12016': 15, 'Q42015': 14, 'Q32015': 13, 'Q22015': 12, 'Q12015': 11, 'Q42014': 10, \n",
    "                'Q32014': 9, 'Q22014': 8, 'Q22014': 7, 'Q12014': 6, 'Q42013': 5, 'Q32013': 4, 'Q22013': 3, \n",
    "                'Q12013': 2, 'Q42012': 1}\n",
    "\n",
    "full_df['quarter_order'] = full_df['quarter'].map(quarter_dict)\n",
    "full_df.sort_values(['lot_number', 'quarter_order'], ascending=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean status column\n",
    "def change(value):\n",
    "    if value['status'] == 'BP Filed': \n",
    "        field = 'BP FILED'\n",
    "        \n",
    "    elif value['status'] == 'PL Filed':\n",
    "        field = 'PL FILED'\n",
    "        \n",
    "    elif value['status'] == 'PL Approved':\n",
    "        field = 'PL APPROVED'\n",
    "        \n",
    "    else: \n",
    "        field = value['status']\n",
    "    return field\n",
    "\n",
    "\n",
    "full_df['status'] = full_df.apply(change, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BP FILED         6664\n",
       "CONSTRUCTION     3206\n",
       "BP ISSUED        2362\n",
       "PL FILED         2106\n",
       "PL APPROVED      1397\n",
       "BP APPROVED       594\n",
       "BP REINSTATED     336\n",
       "BP SUSPEND          1\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['status'].value_counts() #check to see that each category is mutually exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make Quarter variable nicer\n",
    "full_df['quarter'] = full_df['quarter'].str[:2] + '-' + full_df['quarter'].str[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Residential Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, I filter out projects that have no impact on residential development. I define these as those projects with either both zeros for total units and total net units constructed or both nulls for total units and total net units constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out those observations that have no impact on residential construction (0 or null net units and 0 or null units)\n",
    "full_df_res = full_df[(full_df['units'] != 0) | (full_df['net_units'] != 0)]\n",
    "full_df_res = full_df_res[(full_df_res['units'].notnull()) | (full_df_res['net_units'].notnull())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I create a new variable to order the quarters in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#export data to csv\n",
    "export_path = '../../Intermediate Files'\n",
    "full_df_res.to_csv(export_path+'/pipeline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export Commercial Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I filter out projects that have no impact on commercial development. I define these as those projects with either both zeros for total units and total net units constructed or both nulls for total units and total net units constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df_com = full_df[(full_df['comm_sqft'] != 0) | (full_df['comm_sqft_net'] != 0)]\n",
    "full_df_com = full_df_com[(full_df_com['comm_sqft'].notnull()) | (full_df_com['comm_sqft_net'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export data to csv\n",
    "export_path = '../../Intermediate Files'\n",
    "full_df_com.to_csv(export_path+'/pipeline_com.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
