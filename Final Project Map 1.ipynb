{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Map 1\n",
    "## Brian Goggin\n",
    "In this assignment, I use the development pipeline data of SF development in order to create an online map of residential construction by Zillow neighborhood. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import json    # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "import pprint  # library for making Python data structures readable\n",
    "pp = pprint.PrettyPrinter()\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import great_circle\n",
    "from scipy import ndimage\n",
    "import pysal #packaged required for changing mapping schemes (e.g. quantile versus equal interval)\n",
    "import os\n",
    "# magic command to display matplotlib plots inline within the ipython notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Create polygons with recently completed development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine constructed units over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I assume that units were constructed in the latest quarter for which the project had \"construction\" as a project status. I identify these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import_path = \"/Users/briangoggin/Dropbox/CP 255/SF Development Project/Intermediate Files/\"\n",
    "full_df = pd.read_csv(import_path+\"/pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dataframes for line graph of construction, BP, and BI starts over time\n",
    "cons_end = full_df[full_df['status'] == \"CONSTRUCTION\"].groupby(['lot_number'], as_index=False)['quarter_order'].max()\n",
    "cons_end.rename(columns = {'quarter_order': 'consdate'}, inplace = True)\n",
    "#merge data together to identify quarter that projects were built\n",
    "full_df2 = full_df.merge(cons_end, on = 'lot_number', how = \"outer\")\n",
    "full_df2 = full_df2[full_df2['consdate'] == full_df2['quarter_order']]\n",
    "full_df2 = full_df2[full_df2['quarter_order'] != 16]\n",
    "full_df2 = full_df2[full_df2['net_units'].notnull()] #keep only those projects that have nonmissing net units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Point Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crs = {'init' :'epsg:4326'}\n",
    "geometry = [Point(xy) for xy in zip(full_df2.lon, full_df2.lat)]\n",
    "construction = GeoDataFrame(full_df2, crs=crs, geometry=geometry)\n",
    "#construction.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Zillow Neighborhood Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = '/Users/briangoggin/Dropbox/CP 255/SF Development Project/Raw Data'\n",
    "boundaries = gpd.read_file(root+'/ZillowNeighborhoods-CA/ZillowNeighborhoods-CA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boundaries = boundaries[boundaries['COUNTY']=='San Francisco'] #keep only SF neighborhoods\n",
    "#boundaries.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set boundaries into same geographic coordinate system as points\n",
    "boundaries.crs = {'init' :'epsg:4326'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First, spatial join between points and neighborhood boundaries. Set 'how' to 'right' to preserve polygon geometries.\n",
    "nbcum = gpd.sjoin(construction, boundaries, how = 'right', op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Next, dissolve by neighborhoods to get sum of units\n",
    "nbcum['REGIONID'] = nbcum['REGIONID'].astype(int)\n",
    "nbcum = nbcum[['NAME','REGIONID', 'geometry', 'net_units', 'net_affordable_units']]\n",
    "nb_map = nbcum.dissolve(by=['NAME', 'REGIONID'], aggfunc='sum')\n",
    "\n",
    "nb_map['net_units'].fillna(0, inplace = True)\n",
    "nb_map['net_affordable_units'].fillna(0, inplace = True)\n",
    "\n",
    "nb_map['net_units'] = nb_map['net_units'].astype(int)\n",
    "nb_map['net_affordable_units'] = nb_map['net_affordable_units'].astype(int)\n",
    "\n",
    "nb_map['index'] = nb_map.index\n",
    "nb_map['name'] = nb_map['index'].astype(str).str.split(',').str[0].str.strip('(').str.replace(\"'\", '')\n",
    "nb_map['RegionID'] = nb_map['index'].astype(str).str.split(',').str[1].str.strip(')')\n",
    "nb_map.drop('index', axis = 1, inplace = True)\n",
    "#nb_map.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to create categories for javascript maps. Each category will be separate dot color\n",
    "def cats(value):\n",
    "    if (value['net_units'] >=0) & (value['net_units']<=50): \n",
    "        field = 0\n",
    "        \n",
    "    elif (value['net_units'] >=51) & (value['net_units']<=200):\n",
    "        field = 1\n",
    "        \n",
    "    elif (value['net_units'] >=201) & (value['net_units']<=500):\n",
    "        field = 2\n",
    "        \n",
    "    elif (value['net_units'] >=501) & (value['net_units']<=2000):\n",
    "        field = 3\n",
    "    else: \n",
    "        field = 4\n",
    "        \n",
    "    return field\n",
    "\n",
    "\n",
    "nb_map['unitcat'] = nb_map.apply(cats, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#export to geojson object\n",
    "export_path = \"/Users/briangoggin/Dropbox/CP 255/SF Development Project/Code/Pipeline Map\"\n",
    "with open(export_path+'/Neighborhood Maps/nb_recent.js', 'w') as f:\n",
    "    f.write('var dataset = {};'.format(nb_map.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13950"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_map['net_units'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#export data to csv\n",
    "export_path = \"/Users/briangoggin/Dropbox/CP 255/SF Development Project/Intermediate Files/\"\n",
    "nb_map.to_csv(export_path+'/completed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Section 2: Create polygons with currently proposed development only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#isolate currently proposed development\n",
    "current = full_df[full_df['quarter']=='Q22016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create geodataframe for current development\n",
    "crs = {'init' :'epsg:4326'}\n",
    "geometry = [Point(xy) for xy in zip(current.lon, current.lat)]\n",
    "current_geo = GeoDataFrame(current, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First, spatial join between points and neighborhood boundaries. Set 'how' to 'right' to preserve polygon geometries.\n",
    "final_geo = gpd.sjoin(current_geo, boundaries, how = 'right', op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next, dissolve by neighborhoods to get sum of units\n",
    "final_geo['REGIONID'] = final_geo['REGIONID'].astype(int)\n",
    "final_geo = final_geo[['NAME','REGIONID', 'geometry', 'net_units', 'net_affordable_units']]\n",
    "final_geo = final_geo.dissolve(by=['NAME', 'REGIONID'], aggfunc='sum')\n",
    "\n",
    "final_geo['net_units'].fillna(0, inplace = True)\n",
    "final_geo['net_affordable_units'].fillna(0, inplace = True)\n",
    "final_geo['net_units'] = final_geo['net_units'].astype(int)\n",
    "final_geo['net_affordable_units'] = final_geo['net_affordable_units'].astype(int)\n",
    "\n",
    "final_geo['index'] = final_geo.index\n",
    "final_geo['name'] = final_geo['index'].astype(str).str.split(',').str[0].str.strip('(').str.replace(\"'\", '')\n",
    "final_geo['RegionID'] = final_geo['index'].astype(str).str.split(',').str[1].str.strip(')')\n",
    "final_geo.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to create categories for javascript maps. Each category will be separate dot color\n",
    "def cats(value):\n",
    "    if (value['net_units'] >=0) & (value['net_units']<=50): \n",
    "        field = 0\n",
    "        \n",
    "    elif (value['net_units'] >=51) & (value['net_units']<=200):\n",
    "        field = 1\n",
    "        \n",
    "    elif (value['net_units'] >=201) & (value['net_units']<=500):\n",
    "        field = 2\n",
    "        \n",
    "    elif (value['net_units'] >=501) & (value['net_units']<=2000):\n",
    "        field = 3\n",
    "    else: \n",
    "        field = 4\n",
    "        \n",
    "    return field\n",
    "\n",
    "\n",
    "final_geo['unitcat'] = final_geo.apply(cats, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export to geojson object\n",
    "export_path = \"/Users/briangoggin/Dropbox/CP 255/SF Development Project/Code/Pipeline Map\"\n",
    "with open(export_path+'/Neighborhood Maps/nb_current.js', 'w') as f:\n",
    "    f.write('var dataset2 = {};'.format(final_geo.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
