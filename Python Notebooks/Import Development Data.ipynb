{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Import Development Data\n",
    "## Brian Goggin\n",
    "In this assignment, I import data from the San Francisco development pipeline from SF Open data's API. I import quarterly data from the fourth quarter of 2012 to the third quarter of 2016. In the first section of the notebook, I import, append, and clean the data. In other notebooks, I use this data to explore development activity in SF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Import and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the packages necessary for calling an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import json    # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "import pprint  # library for making Python data structures readable\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SF Planning Department releases this data quarterly. Quarterly reports go back all the way to 2012. However, this data is messy and inconsistent. Therefore, for the purposes of this assignment, I have preserved some of the code in comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q32016 = 'https://data.sfgov.org/resource/qwfj-9mts.json'\n",
    "Q22016 = 'https://data.sfgov.org/resource/3n2r-nn4r.json'\n",
    "Q12016 = 'https://data.sfgov.org/resource/6iid-qfaz.json'\n",
    "Q42015 = 'https://data.sfgov.org/resource/6jnk-ty34.json'\n",
    "Q32015 = 'https://data.sfgov.org/resource/8qip-pyye.json'\n",
    "Q22015 = 'https://data.sfgov.org/resource/b6nb-tyvq.json'\n",
    "Q12015 = 'https://data.sfgov.org/resource/auw5-vpae.json'\n",
    "Q42014 = 'https://data.sfgov.org/resource/ia2z-a7eh.json'\n",
    "Q32014 = 'https://data.sfgov.org/resource/9xqb-guwy.json' #Problem - this json does not have best date information that the raw csv file does\n",
    "Q22014 = 'https://data.sfgov.org/resource/tkr2-mzci.json'\n",
    "Q12014 = 'https://data.sfgov.org/resource/fq62-z4pc.json'\n",
    "Q42013 = 'https://data.sfgov.org/resource/s42z-x9np.json'\n",
    "Q32013 = 'https://data.sfgov.org/resource/h2ky-3rra.json'\n",
    "Q22013 = 'https://data.sfgov.org/resource/ixti-hd8i.json'\n",
    "Q12013 = 'https://data.sfgov.org/resource/662u-bk2r.json'\n",
    "Q42012 = 'https://data.sfgov.org/resource/fpzh-9ii5.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I define a function for importing the data from each API into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importdata(quarter, quartervalue, field1, field2, field3, field4, field5, field6, field7, field8, field9, field10, geogfield1, geogfield2):\n",
    "    '''\n",
    "    This function calls the API endpoint quarter and returns a dataframe with the desired columns.\n",
    "    field'n' = 'name' represent the desired fields as they are named at the API endpoint\n",
    "    '''\n",
    "    \n",
    "    def includekey(field):\n",
    "        '''\n",
    "        This function takes a given field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if field in item.keys():\n",
    "                list.append(item[field])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "\n",
    "    def include_coor_key(one, two):\n",
    "        '''\n",
    "        This function takes a given geographic field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if one in item.keys():\n",
    "                list.append(item[one][two])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "    \n",
    "    response = requests.get(quarter)\n",
    "    results = response.text\n",
    "    data = json.loads(results) #data is a list at this point\n",
    "    \n",
    "    #import fields\n",
    "    d = {}\n",
    "    d['lot_number'] = includekey(field1)\n",
    "    d['address'] = includekey(field2)\n",
    "    d['status'] = includekey(field3)\n",
    "    d['latest_date'] = includekey(field4)\n",
    "    d['units'] = includekey(field5)\n",
    "    d['net_units'] = includekey(field6)\n",
    "    d['affordable_units'] = includekey(field7)\n",
    "    d['net_affordable_units'] = includekey(field8)\n",
    "    d['zone'] = includekey(field9)\n",
    "    d['desc'] = includekey(field10)\n",
    "    d['lat_lon'] = include_coor_key(geogfield1, geogfield2)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    df['quarter'] = quartervalue\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the data (one for each quarter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q32016df = importdata(Q32016, 'Q32016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affnet', 'zoning_sim', 'dbidesc', 'location', 'coordinates')\n",
    "Q22016df = importdata(Q22016, 'Q22016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'aff', 'affnet', 'zoning_sim', 'dbi_desc', 'location', 'coordinates')   \n",
    "Q12016df = importdata(Q12016, 'Q12016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordable_net', 'zoning', 'dbidesc', 'location', 'coordinates')\n",
    "Q42015df = importdata(Q42015, 'Q42015','apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordab_1', 'zoning_sim','dbidesc', 'geography', 'coordinates')\n",
    "Q32015df = importdata(Q32015, 'Q32015','apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordablenet', 'zoning_sim', 'dbidesc', 'location', 'coordinates')\n",
    "Q22015df = importdata(Q22015,'Q22015', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordablenet', 'zoning_sim', 'dbidesc','geography', 'coordinates')\n",
    "Q12015df = importdata(Q12015, 'Q12015','blklot', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'aff', 'affnet', 'zoning_sim','dbidesc', 'geography', 'coordinates')\n",
    "Q42014df = importdata(Q42014, 'Q42014','blklot', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affnet', 'zoning_sim', 'dbidesc', 'geography', 'coordinates')\n",
    "Q32014df = importdata(Q32014, 'Q32014','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affnet', 'zoning', 'dbi_project_description', 'location_1', 'coordinates')\n",
    "Q22014df = importdata(Q22014, 'Q22014','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'planning_project_description', 'location_1', 'coordinates')\n",
    "Q12014df = importdata(Q12014,'Q12014', 'block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified','planning_project_description', 'location_1', 'coordinates')\n",
    "Q42013df = importdata(Q42013,'Q42013', 'block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified','planning_project_description', 'location_1', 'coordinates')\n",
    "Q32013df = importdata(Q32013, 'Q32013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'planning_project_description', 'location_1', 'coordinates')\n",
    "Q22013df = importdata(Q22013, 'Q22013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'dbi_project_description', 'location_1', 'coordinates')\n",
    "Q12013df = importdata(Q12013, 'Q12013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'dbi_project_description', 'location_1', 'coordinates')\n",
    "Q42012df = importdata(Q42012, 'Q42012','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'dbi_project_description', 'location_1', 'coordinates')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the dataframes together for one panel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14666, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Append data together\n",
    "quarters = [Q22016df, Q12016df, Q42015df, Q32015df, Q22015df, Q12015df, Q42014df, \n",
    "            Q32014df, Q22014df, Q12014df, Q42013df, Q32013df, Q22013df, Q12013df,\n",
    "           Q42012df]\n",
    "full_df = Q32016df.append(quarters)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data after appending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean affordable units variables\n",
    "full_df.loc[full_df['affordable_units'] == '0E-11', 'affordable_units'] = 0\n",
    "full_df.loc[full_df['net_affordable_units'] == '0E-11', 'net_affordable_units'] = 0\n",
    "#full_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean data after importing\n",
    "full_df['lon'] = full_df['lat_lon'].astype(str).str.split(',').str[0].str.strip('[')\n",
    "full_df['lat'] = full_df['lat_lon'].astype(str).str.split(',').str[1].str.strip(']')\n",
    "full_df['lon'] = full_df['lon'].astype(float)\n",
    "full_df['lat'] = full_df['lat'].astype(float)\n",
    "full_df['net_units'] = full_df['net_units'].astype(float) #convert to float\n",
    "full_df['units'] = full_df['units'].astype(float) #convert to float\n",
    "full_df['net_affordable_units'] = full_df['net_affordable_units'].astype(float) #convert to float\n",
    "full_df['affordable_units'] = full_df['affordable_units'].astype(float) #convert to float\n",
    "full_df['lot_number'] = full_df['lot_number'].str.strip('APN ').str.zfill(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I filter out projects that have no impact on residential development. I define these as those projects with either both zeros for total units and total net units constructed or both nulls for total units and total net units constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out those observations that have no impact on residential construction (0 or null net units and 0 or null units)\n",
    "full_df = full_df[(full_df['units'] != 0) | (full_df['net_units'] != 0)]\n",
    "full_df = full_df[(full_df['units'].notnull()) | (full_df['net_units'].notnull())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I create a new variable to order the quarters in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dictionary for which quarter a project is in and then sort by quarters\n",
    "quarter_dict = {'Q32016': 17, 'Q22016': 16, 'Q12016': 15, 'Q42015': 14, 'Q32015': 13, 'Q22015': 12, 'Q12015': 11, 'Q42014': 10, \n",
    "                'Q32014': 9, 'Q22014': 8, 'Q22014': 7, 'Q12014': 6, 'Q42013': 5, 'Q32013': 4, 'Q22013': 3, \n",
    "                'Q12013': 2, 'Q42012': 1}\n",
    "\n",
    "full_df['quarter_order'] = full_df['quarter'].map(quarter_dict)\n",
    "full_df.sort_values(['lot_number', 'quarter_order'], ascending=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I clean up the project status variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean status column\n",
    "def change(value):\n",
    "    if value['status'] == 'BP Filed': \n",
    "        field = 'BP FILED'\n",
    "        \n",
    "    elif value['status'] == 'PL Filed':\n",
    "        field = 'PL FILED'\n",
    "        \n",
    "    elif value['status'] == 'PL Approved':\n",
    "        field = 'PL APPROVED'\n",
    "        \n",
    "    else: \n",
    "        field = value['status']\n",
    "    return field\n",
    "\n",
    "\n",
    "full_df['status'] = full_df.apply(change, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BP FILED         5321\n",
       "CONSTRUCTION     2657\n",
       "BP ISSUED        1885\n",
       "PL FILED         1563\n",
       "PL APPROVED      1135\n",
       "BP APPROVED       484\n",
       "BP REINSTATED     305\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['status'].value_counts() #check to see that each category is mutually exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make Quarter variable nicer\n",
    "full_df['quarter'] = full_df['quarter'].str[:2] + '-' + full_df['quarter'].str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#export data to csv\n",
    "export_path = \"/Users/briangoggin/Dropbox/CP 255/SF Development Project/Intermediate Files/\"\n",
    "full_df.to_csv(export_path+'/pipeline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
