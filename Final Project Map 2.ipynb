{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Map 2\n",
    "## Brian Goggin\n",
    "In this assignment, I use the development pipeline data of SF development in order to create an online map of residential construction at the point level. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import json    # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "import pprint  # library for making Python data structures readable\n",
    "pp = pprint.PrettyPrinter()\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import great_circle\n",
    "from scipy import ndimage\n",
    "import pysal #packaged required for changing mapping schemes (e.g. quantile versus equal interval)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine constructed unites over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I assume that units were constructed in the latest quarter for which the project had \"construction\" as a project status. I identify these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import_path = \"/Users/briangoggin/Dropbox/CP 255/SF Development Project/Intermediate Files/\"\n",
    "full_df = pd.read_csv(import_path+\"/pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vars = ['net_units', 'net_affordable_units']\n",
    "#do some initial data cleaning\n",
    "for item in vars:\n",
    "    full_df[item] = full_df[item].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Create Recent Completions Geojson File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create dataframes for line graph of construction, BP, and BI starts over time\n",
    "cons_end = full_df[full_df['status'] == \"CONSTRUCTION\"].groupby(['lot_number'], as_index=False)['quarter_order'].max()\n",
    "cons_end.rename(columns = {'quarter_order': 'consdate'}, inplace = True)\n",
    "#merge data together to identify quarter that projects were built\n",
    "full_df2 = full_df.merge(cons_end, on = 'lot_number', how = \"outer\")\n",
    "full_df2 = full_df2[full_df2['consdate'] == full_df2['quarter_order']]\n",
    "full_df2 = full_df2[full_df2['quarter_order'] != 16]\n",
    "full_df2 = full_df2[full_df2['net_units'].notnull()] #keep only those projects that have nonmissing net units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define function to create categories for javascript maps. Each category will be separate dot color\n",
    "def cats(value):\n",
    "    if value['net_units'] <0: \n",
    "        field = 0\n",
    "        \n",
    "    elif (value['net_units'] >=0) & (value['net_units']<=15):\n",
    "        field = 1\n",
    "        \n",
    "    elif (value['net_units'] >=16) & (value['net_units']<=30):\n",
    "        field = 2\n",
    "        \n",
    "    elif (value['net_units'] >=31) & (value['net_units']<=50):\n",
    "        field = 3\n",
    "        \n",
    "    elif (value['net_units'] >=51) & (value['net_units']<=100):\n",
    "        field = 4  \n",
    "        \n",
    "    else: \n",
    "        field = 5\n",
    "        \n",
    "    return field\n",
    "\n",
    "\n",
    "full_df2['unitcat'] = full_df2.apply(cats, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Point Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write function for dataframe\n",
    "def df_to_geojson(df, properties, lat='latitude', lon='longitude'):\n",
    "    # create a new python dict to contain our geojson data, using geojson format\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "\n",
    "    # loop through each row in the dataframe and convert each row to geojson format\n",
    "    for _, row in df.iterrows():\n",
    "        # create a feature template to fill in\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{},\n",
    "                   'geometry':{'type':'Point',\n",
    "                               'coordinates':[]}}\n",
    "\n",
    "        # fill in the coordinates\n",
    "        feature['geometry']['coordinates'] = [row[lon],row[lat]]\n",
    "\n",
    "        # for each column, get the value and add it as a new feature property\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        \n",
    "        # add this feature (aka, converted dataframe row) to the list of features inside our dict\n",
    "        geojson['features'].append(feature)\n",
    "    \n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finally, create dataframe\n",
    "cols = ['net_units', 'net_affordable_units', 'address', 'quarter', 'zone', 'unitcat']\n",
    "geojson = df_to_geojson(full_df2, cols, 'lat', 'lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the geojson result to a file\n",
    "folder = '/Users/briangoggin/Dropbox/CP 255/SF Development Project/Intermediate Files/'\n",
    "output_filename = folder+'/recent_data.js'\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    output_file.write('var dataset = {};'.format(json.dumps(geojson, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Create Geojson for Current Development Projects in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current = full_df[full_df['quarter']=='Q22016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briangoggin/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "current['unitcat'] = current.apply(cats, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finally, create dataframe\n",
    "cols = ['net_units', 'net_affordable_units', 'address', 'quarter', 'zone', 'unitcat', 'status']\n",
    "geojson = df_to_geojson(current, cols, 'lat', 'lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the geojson result to a file\n",
    "folder = '/Users/briangoggin/Dropbox/CP 255/SF Development Project/Intermediate Files/'\n",
    "output_filename = folder+'/current_data.js'\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    output_file.write('var dataset2 = {};'.format(json.dumps(geojson, indent=4)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
