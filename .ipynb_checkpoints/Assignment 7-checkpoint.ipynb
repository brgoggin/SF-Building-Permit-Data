{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "## Brian Goggin\n",
    "In this assignment, I import data from the San Francisco development pipeline from SF Open data's API. I import quarterly data from the fourth quarter of 2012 to the second quarter of 2016. In the first section of the notebook, I import, append, and clean the data. In the second section, I create 4 graphs to explore the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Import and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the packages necessary for calling an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re as re\n",
    "import json    # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "import pprint  # library for making Python data structures readable\n",
    "pp = pprint.PrettyPrinter()\n",
    "from altair import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SF Planning Department releases this data quarterly. Quarterly reports go back all the way to 2012. However, this data is messy and inconsistent. Therefore, for the purposes of this assignment, I have preserved some of the code in comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q22016 = 'https://data.sfgov.org/resource/3n2r-nn4r.json'\n",
    "Q12016 = 'https://data.sfgov.org/resource/6iid-qfaz.json'\n",
    "Q42015 = 'https://data.sfgov.org/resource/6jnk-ty34.json'\n",
    "Q32015 = 'https://data.sfgov.org/resource/8qip-pyye.json'\n",
    "Q22015 = 'https://data.sfgov.org/resource/b6nb-tyvq.json'\n",
    "Q12015 = 'https://data.sfgov.org/resource/auw5-vpae.json'\n",
    "Q42014 = 'https://data.sfgov.org/resource/ia2z-a7eh.json'\n",
    "Q32014 = 'https://data.sfgov.org/resource/9xqb-guwy.json' #Problem - this json does not have best date information that the raw csv file does\n",
    "Q22014 = 'https://data.sfgov.org/resource/tkr2-mzci.json'\n",
    "Q12014 = 'https://data.sfgov.org/resource/fq62-z4pc.json'\n",
    "Q42013 = 'https://data.sfgov.org/resource/s42z-x9np.json'\n",
    "Q32013 = 'https://data.sfgov.org/resource/h2ky-3rra.json'\n",
    "Q22013 = 'https://data.sfgov.org/resource/ixti-hd8i.json'\n",
    "Q12013 = 'https://data.sfgov.org/resource/662u-bk2r.json'\n",
    "Q42012 = 'https://data.sfgov.org/resource/fpzh-9ii5.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I define a function for importing the data from each API into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importdata(quarter, quartervalue, field1, field2, field3, field4, field5, field6, field7, field8, field9, geogfield1, geogfield2):\n",
    "    '''\n",
    "    This function calls the API endpoint quarter and returns a dataframe with the desired columns.\n",
    "    field1=geogfield2 represent the desired fields as they are named at the API endpoint\n",
    "    '''\n",
    "    \n",
    "    def includekey(field):\n",
    "        '''\n",
    "        This function takes a given field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if field in item.keys():\n",
    "                list.append(item[field])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "\n",
    "    def include_coor_key(one, two):\n",
    "        '''\n",
    "        This function takes a given geographic field from the API endpoint and creates a list out of its entires.\n",
    "        '''\n",
    "        list = []\n",
    "        for item in data: \n",
    "            if one in item.keys():\n",
    "                list.append(item[one][two])\n",
    "            else:\n",
    "                list.append(np.nan)\n",
    "        return list\n",
    "    \n",
    "    response = requests.get(quarter)\n",
    "    results = response.text\n",
    "    data = json.loads(results) #data is a list at this point\n",
    "    \n",
    "    #import fields\n",
    "    d = {}\n",
    "    d['lot_number'] = includekey(field1)\n",
    "    d['address'] = includekey(field2)\n",
    "    d['status'] = includekey(field3)\n",
    "    d['latest_date'] = includekey(field4)\n",
    "    d['units'] = includekey(field5)\n",
    "    d['net_units'] = includekey(field6)\n",
    "    d['affordable_units'] = includekey(field7)\n",
    "    d['net_affordable_units'] = includekey(field8)\n",
    "    d['zone'] = includekey(field9)\n",
    "    d['lat_lon'] = include_coor_key(geogfield1, geogfield2)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    df['quarter'] = quartervalue\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the data (one for each quarter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q22016df = importdata(Q22016, 'Q22016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'aff', 'affnet', 'zoning_sim', 'location', 'coordinates')   \n",
    "Q12016df = importdata(Q12016, 'Q12016', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordable_net', 'zoning', 'location', 'coordinates')\n",
    "Q42015df = importdata(Q42015, 'Q42015','apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordab_1', 'zoning_sim', 'geography', 'coordinates')\n",
    "Q32015df = importdata(Q32015, 'Q32015','apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordablenet', 'zoning_sim', 'location', 'coordinates')\n",
    "Q22015df = importdata(Q22015,'Q22015', 'apn', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affordablenet', 'zoning_sim', 'geography', 'coordinates')\n",
    "Q12015df = importdata(Q12015, 'Q12015','blklot', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'aff', 'affnet', 'zoning_sim', 'geography', 'coordinates')\n",
    "Q42014df = importdata(Q42014, 'Q42014','blklot', 'nameaddr', 'beststat', 'bestdate', 'units', 'unitsnet', 'affordable', 'affnet', 'zoning_sim', 'geography', 'coordinates')\n",
    "Q32014df = importdata(Q32014, 'Q32014','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affnet', 'zoning', 'location_1', 'coordinates')\n",
    "Q22014df = importdata(Q22014, 'Q22014','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'location_1', 'coordinates')\n",
    "Q12014df = importdata(Q12014,'Q12014', 'block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'location_1', 'coordinates')\n",
    "Q42013df = importdata(Q42013,'Q42013', 'block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'location_1', 'coordinates')\n",
    "Q32013df = importdata(Q32013, 'Q32013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'location_1', 'coordinates')\n",
    "Q22013df = importdata(Q22013, 'Q22013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'location_1', 'coordinates')\n",
    "Q12013df = importdata(Q12013, 'Q12013','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'location_1', 'coordinates')\n",
    "Q42012df = importdata(Q42012, 'Q42012','block_lot', 'location_1_address', 'best_stat', 'best_date', 'units', 'net_added_units', 'affordable', 'affordablenet', 'zoning_simplified', 'location_1', 'coordinates')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the dataframes together for one panel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Append data together\n",
    "quarters = [Q12016df, Q42015df, Q32015df, Q22015df, Q12015df, Q42014df, \n",
    "            Q32014df, Q22014df, Q12014df, Q42013df, Q32013df, Q22013df, Q12013df,\n",
    "           Q42012df]\n",
    "full_df = Q22016df.append(quarters)\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data after appending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean data after importing\n",
    "full_df['lon'] = full_df['lat_lon'].astype(str).str.split(',').str[0].str.strip('[')\n",
    "full_df['lat'] = full_df['lat_lon'].astype(str).str.split(',').str[1].str.strip(']')\n",
    "full_df['net_units'] = full_df['net_units'].astype(float) #convert to float\n",
    "full_df['units'] = full_df['units'].astype(float) #convert to float\n",
    "full_df['net_affordable_units'] = full_df['net_affordable_units'].astype(float) #convert to float\n",
    "full_df['affordable_units'] = full_df['affordable_units'].astype(float) #convert to float\n",
    "full_df['lot_number'] = full_df['lot_number'].str.strip('APN ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I filter out projects that have no impact on residential development. I define these as those projects with either both zeros for total units and total net units constructed or both nulls for total units and total net units constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out those observations that have no impact on residential construction (0 or null net units and 0 or null units)\n",
    "full_df = full_df[(full_df['units'] != 0) | (full_df['net_units'] != 0)]\n",
    "full_df = full_df[(full_df['units'].notnull()) | (full_df['net_units'].notnull())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I create a new variable to order the quarters in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dictionary for which quarter a project is in and then sort by quarters\n",
    "quarter_dict = {'Q22016': 16, 'Q12016': 15, 'Q42015': 14, 'Q32015': 13, 'Q22015': 12, 'Q12015': 11, 'Q42014': 10, \n",
    "                'Q32014': 9, 'Q22014': 8, 'Q22014': 7, 'Q12014': 6, 'Q42013': 5, 'Q32013': 4, 'Q22013': 3, \n",
    "                'Q12013': 2, 'Q42012': 1}\n",
    "\n",
    "full_df['quarter_order'] = full_df['quarter'].map(quarter_dict)\n",
    "full_df.sort_values(['lot_number', 'quarter_order'], ascending=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I clean up the project status variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean status column\n",
    "def change(value):\n",
    "    if value['status'] == 'BP Filed': \n",
    "        field = 'BP FILED'\n",
    "        \n",
    "    elif value['status'] == 'PL Filed':\n",
    "        field = 'PL FILED'\n",
    "        \n",
    "    elif value['status'] == 'PL Approved':\n",
    "        field = 'PL APPROVED'\n",
    "        \n",
    "    else: \n",
    "        field = value['status']\n",
    "    return field\n",
    "\n",
    "\n",
    "full_df['status'] = full_df.apply(change, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_df['status'].value_counts() #check to see that each category is mutually exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Make Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 1: Current Development Status\n",
    "\n",
    "First, I graph the amount of net units by the status of the projects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bar graph of current development snapshot\n",
    "data = full_df[full_df['quarter'] == 'Q22016']\n",
    "\n",
    "#drop some outliers (greater than 10,000 units)\n",
    "data = data[data['net_units'] < 5000]\n",
    "\n",
    "Chart(data).mark_bar().encode(\n",
    "    x=X('status', axis = Axis(title = 'Project Status')), \n",
    "    y=Y('sum(net_units)', axis = Axis(title = 'Total Net Units')), \n",
    ").configure_scale(\n",
    "    bandSize=50  # scale.bandSize adjusts thickness (in pixels) of bars\n",
    ").configure_cell(\n",
    "    width=200  # cell.width adjusts the width (in pixels) of the chart\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows the total number of net units (additions minus demolitions) currently on the docket in San Francisco by the status. Interestingly, the largest category are projects that have filed for planning review but not yet received planning approval. To put this in context, the total number of new units allocated for San Francisco County as part of the Association of Bay Area Government's (ABAG) Regional Housing Needs Assessment is 28,869 (pg. 24). This is the amount of housing that state and local law mandate that San Francisco has to plan for between 2014-2022. If about 7,000 new units are constructed every year, it would appear that San Francisco is on track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 2: Total versus Net Units\n",
    "\n",
    "Next, I chart the amount of net units versus total units by project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop even more outliers for scatter plot (greater than 2,000 units)\n",
    "data = data[data['net_units'] < 2000]\n",
    "\n",
    "Chart(data).mark_point().encode(\n",
    "    x=X('units', axis = Axis(title = 'Total Units')),\n",
    "    y=Y('net_units', axis = Axis(title = 'Total Net Units')),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatter plot shows the relationship between units and net units for all residential projects in the second quarter of 2016. This mostly follows a straight line, illustrating that the new units added for most projects is equivalent to the gains in units for that lot. Furthermore, notice that most of the projects have positive total net units, indicating that almost every project adds more units than it takes away. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 3: Market Rate Versus Affordable Units\n",
    "\n",
    "Next, I chart the amount of total net units versus total net affordable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Chart(data).mark_point().encode( \n",
    "    x=X('net_affordable_units', axis = Axis(title = 'Total Net Affordable Units')),\n",
    "    y=Y('net_units', axis = Axis(title = 'Total Net Units')),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatter plot shows total net units compared to total net affordable units built on site. Affordable units are those typically built for people between 20% and 60% of the area's median income. As we can see in the plot above, most projects add far more market-rate units than affordable units. However, there are some interesting outliers, such as the project at the far right end of the chart. This is Hope SF Sunnydale, a project by the San Francisco Housing Authority that will add 915 units of affordable housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph 4: Total Net Units Built Over Time\n",
    "\n",
    "Finally, I chart the total net units built over time (Quarter 4 2012 - Quarter 2 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I assume that units were constructed in the latest quarter for which the project had \"construction\" as a project status. I identify these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dataframes for line graph of construction, BP, and BI starts over time\n",
    "cons_end = full_df[full_df['status'] == \"CONSTRUCTION\"].groupby(['lot_number'], as_index=False)['quarter_order'].max()\n",
    "cons_end.rename(columns = {'quarter_order': 'consdate'}, inplace = True)\n",
    "#merge data together to identify quarter that projects were built\n",
    "full_df2 = full_df.merge(cons_end, on = 'lot_number', how = \"outer\")\n",
    "full_df2 = full_df2[full_df2['consdate'] == full_df2['quarter_order']]\n",
    "full_df2 = full_df2[full_df2['quarter_order'] != 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finally, create a quarter variable that is more readable for the x-axis. \n",
    "quarter_dict = {'Q22016': '2016-Q2', 'Q12016': '2016-Q1', 'Q42015': '2015-Q4', 'Q32015': '2015-Q3', 'Q22015': '2015-Q2', \n",
    "                'Q12015': '2015-Q1', 'Q42014': '2014-Q4', 'Q32014': '2014-Q3', 'Q22014': '2014-Q2', 'Q12014': '2014-Q1', \n",
    "                'Q42013': '2013-Q4', 'Q32013': '2013-Q3', 'Q22013': '2013-Q2', \n",
    "                'Q12013': '2013-Q1', 'Q42012': '2012-Q4'}\n",
    "\n",
    "full_df2['quarter2'] = full_df2['quarter'].map(quarter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Chart(full_df2).mark_area().encode(\n",
    "    x=X('quarter2', axis = Axis(title = 'Quarter')),\n",
    "    y=Y('sum(net_units):Q', axis = Axis(title = 'Total Net Units Built')),\n",
    ").configure_cell(\n",
    "    height=300.0,\n",
    "    width=1000.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I chart total net units built over time where the x-axis is the quarter of the year (e.g. Q1 is January 1 - March 31). The time period spans from the fourth quarter of 2012 to the first quarter of 2016. The chart shows that units built vary a lot over time and there does not appear to be a clear trend towards more or less construction. If anything, there has been more units completed in recent quarters than in the beginning of the time period. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
